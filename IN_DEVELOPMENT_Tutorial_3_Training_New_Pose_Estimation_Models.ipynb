{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26NhmulM9Nx_"
      },
      "source": [
        "# Pose Estimation - Training Models from New Datasets\n",
        "\n",
        "References: https://docs.ultralytics.com/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXM8fZY4839G",
        "outputId": "36b58d35-1992-4a17-cae1-40ddf6f6e8f9"
      },
      "outputs": [],
      "source": [
        "#!pip install -U ultralytics\n",
        "import ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPmsuJWP9TNW"
      },
      "source": [
        "## Training a New Model to Detect Hand Keypoints\n",
        "\n",
        "As we saw in the live demo, the out-of-the-box pose estimation model does not support articulation of finger movement or other fine hand gestures. We will now use the Hand Keypoints dataset (available through the Ultralytics API) to train a new model that is capable of this functionality, and demo it live on our webcam.\n",
        "\n",
        "https://docs.ultralytics.com/datasets/pose/hand-keypoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQF_QFsk9CTo",
        "outputId": "6d3b2013-6b28-4170-d469-c419ba31b82f"
      },
      "outputs": [],
      "source": [
        "# Load copy of pretrained model and train on Hand Keypoints dataset:\n",
        "\n",
        "hand_model = YOLO(\"yolo11n-pose.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model\n",
        "hand_train_results = hand_model.train(data=\"hand-keypoints.yaml\", epochs=100, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3F-Ss6BtbHI"
      },
      "outputs": [],
      "source": [
        "# Save \"hand_model\" as \"hand_model.pt\" and then download\n",
        "hand_model.save(\"hand_model.pt\")\n",
        "files.download(\"hand_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Drn1M6Q9Ek3"
      },
      "outputs": [],
      "source": [
        "# In the interest of time, we will not train this model live, but you can download one that I trained ahead of time here:\n",
        "\n",
        "# add code to download and save model once it is trained and hosted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duSDsMC8xS6A"
      },
      "source": [
        "We will now return to the \"YOLO_pose.py\" file we used in the earlier demo, and see how this model performs on a live webcam feed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HBKyjRbCixn"
      },
      "source": [
        "## Train a New Model to Detect Animal Poses:\n",
        "We have seen out-of-the-box inference based on the COCO dataset, as well as the new functionality provided by the Hand Keypoints dataset. Now we will train one last model, this time to predict keypoints on tigers.\n",
        "\n",
        "Finally, we will see how this new model can be used to run real-time inference on a video of tigers from YouTube (sorry, we didn't have any tigers available live for this demo).\n",
        "\n",
        "https://docs.ultralytics.com/datasets/pose/tiger-pose/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7YyGoH-CMRB"
      },
      "outputs": [],
      "source": [
        "# Load a fresh copy of the pretrained model:\n",
        "tiger_model = YOLO(\"yolo11n-pose.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Train the model on Tiger-Pose dataset:\n",
        "tiger_train_results = tiger_model.train(data=\"tiger-pose.yaml\", epochs=100, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDZ6B8yvxnuT"
      },
      "outputs": [],
      "source": [
        "# In the interest of time, we will not train this model live, but you can download one that I trained ahead of time here:\n",
        "\n",
        "# add code to download and save model once it is trained and hosted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZzHh7xix-is"
      },
      "source": [
        "Now we will now to the \"YOLO_pose.py\" file again, and see how this model performs on YouTube video of a tiger."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
